@inproceedings{C:LaBRI::PMAA2008b,
 abstract = {Over the past few years, parallel sparse direct solvers made significant progress and are now able to solve efficiently industrial three-dimensional problems with several millions of unknowns. An hybrid MPI-thread implementation of our direct solver PaStiX is already well suited for SMP nodes or new multi-core architectures and drastically reduced the memory overhead and improved scalability. In the context of distributed NUMA architectures, a dynamic scheduler based on a work-stealing algorithm has been developed to fill in communication idle times.  On these architectures, it is important to take care of NUMA effects and to preserve memory affinity during the work-stealing. The scheduling of communications also needs to be adapted, especially to ensure the overlap by computations. Experiments on numerical test cases will be presented to prove the efficiency of the approach on NUMA architectures. If memory is not large enough to treat a given problem, disks must be used to store data that cannot fit in memory (out-of-core storage). The idle-times due to disk access have to be managed by our dynamic scheduler to prefetch and save datasets. Thus, we design and study specific scheduling algorithms in this particular context.},
 address = {Neuchatel, Swiss},
 author = {Faverge, M. and Lacoste, X. and Ramet, P.},
 booktitle = {Proceedings of PMAA'2008},
 keywords = {Sparse},
 month = {June},
 optannote = {},
 optcrossref = {},
 opteditor = {},
 optkey = {},
 optnote = {},
 optnumber = {},
 optorganization = {},
 optpages = {},
 optpublisher = {},
 optseries = {},
 opturl = {},
 optvolume = {},
 title = {A NUMA Aware Scheduler for a Parallel Sparse Direct Solver},
 year = {2008}
}
